{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from natsort import natsorted\n",
    "import math\n",
    "import pandas as pd\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "stop_words = set(stopwords.words(\"english\")) - set([\"in\", \"to\", \"where\"])\n",
    "positional_index = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing and Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_and_tokenize_documents(directory_path):\n",
    "    files_name = natsorted(os.listdir(directory_path))\n",
    "    document_of_terms = []\n",
    "    stemmed_dict = {}\n",
    "\n",
    "    for files in files_name:\n",
    "        with open(os.path.join(directory_path, files), \"r\") as f:\n",
    "            document = f.read()\n",
    "        stemmed_doc = tokenize_and_stem(document, stemmed_dict)\n",
    "        document_of_terms.append(stemmed_doc)\n",
    "\n",
    "    return document_of_terms, stemmed_dict\n",
    "\n",
    "\n",
    "def tokenize_and_stem(doc, stemmed_dict):\n",
    "    token_docs = word_tokenize(doc)\n",
    "    prepared_doc = [stem(token, stemmed_dict) for token in token_docs if token.lower() not in stop_words]\n",
    "    return prepared_doc\n",
    "\n",
    "def tokenize(doc):\n",
    "    token_docs = word_tokenize(doc)\n",
    "    prepared_doc = [token for token in token_docs if token.lower() not in stop_words]\n",
    "    return prepared_doc\n",
    "\n",
    "def stem(token, stemmed_dict):\n",
    "    stem_term = PorterStemmer().stem(token.lower())\n",
    "    stemmed_dict[stem_term] = token.lower()\n",
    "    return stem_term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_directory_path = \"docs\"\n",
    "document_of_terms, stemmed_dict = read_and_tokenize_documents(docs_directory_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# POSITIONAL INDEX MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_positional_index(document_of_terms):\n",
    "    for doc_id, document in enumerate(document_of_terms, start=1):\n",
    "        for position, term in enumerate(document):\n",
    "            if term not in positional_index:\n",
    "                positional_index[term] = [0, {}]\n",
    "            positional_index[term][0] += 1\n",
    "            positional_index[term][1].setdefault(doc_id, []).append(position)\n",
    "    return positional_index\n",
    "\n",
    "def get_key_by_value(dictionary, target_value, default=None):\n",
    "    \"\"\"Get the key for a given value in a dictionary.\"\"\"\n",
    "    return next((key for key, value in dictionary.items() if value == target_value), default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'antoni': [3, {1: [0], 2: [0], 6: [0]}],\n",
       " 'brutu': [3, {1: [1], 2: [1], 4: [0]}],\n",
       " 'caeser': [5, {1: [2], 2: [2], 4: [1], 5: [0], 6: [1]}],\n",
       " 'cleopatra': [1, {1: [3]}],\n",
       " 'merci': [5, {1: [4], 3: [0], 4: [2], 5: [1], 6: [2]}],\n",
       " 'worser': [4, {1: [5], 3: [1], 4: [3], 5: [2]}],\n",
       " 'calpurnia': [1, {2: [3]}],\n",
       " 'angel': [3, {7: [0], 8: [0], 9: [0]}],\n",
       " 'fool': [4, {7: [1], 8: [1], 9: [1], 10: [0]}],\n",
       " 'fear': [3, {7: [2], 8: [2], 10: [1]}],\n",
       " 'in': [4, {7: [3], 8: [3], 9: [2], 10: [2]}],\n",
       " 'rush': [4, {7: [4], 8: [4], 9: [3], 10: [3]}],\n",
       " 'to': [4, {7: [5], 8: [5], 9: [4], 10: [4]}],\n",
       " 'tread': [4, {7: [6], 8: [6], 9: [5], 10: [5]}],\n",
       " 'where': [4, {7: [7], 8: [7], 9: [6], 10: [6]}]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "build_positional_index(document_of_terms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TERM-FREQUANCY.TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_term_frequency_dataframe(positional_index, stemmed_dict):\n",
    "    term_frequency = {}\n",
    "    for stem_term, (_, postings) in positional_index.items():\n",
    "        term = stemmed_dict.get(stem_term, stem_term)\n",
    "        term_frequency[term] = {}\n",
    "        for doc_id, positions in postings.items():\n",
    "            col_name = f\"doc_{doc_id}\"\n",
    "            term_frequency[term][col_name] = len(positions)\n",
    "    df = pd.DataFrame.from_dict(term_frequency, orient='index')\n",
    "    df = df.fillna(0)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_1</th>\n",
       "      <th>doc_2</th>\n",
       "      <th>doc_6</th>\n",
       "      <th>doc_4</th>\n",
       "      <th>doc_5</th>\n",
       "      <th>doc_3</th>\n",
       "      <th>doc_7</th>\n",
       "      <th>doc_8</th>\n",
       "      <th>doc_9</th>\n",
       "      <th>doc_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>antony</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brutus</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>caeser</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cleopatra</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mercy</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worser</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>calpurnia</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>angels</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fools</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fear</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rush</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tread</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>where</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           doc_1  doc_2  doc_6  doc_4  doc_5  doc_3  doc_7  doc_8  doc_9  \\\n",
       "antony       1.0    1.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "brutus       1.0    1.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0   \n",
       "caeser       1.0    1.0    1.0    1.0    1.0    0.0    0.0    0.0    0.0   \n",
       "cleopatra    1.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "mercy        1.0    0.0    1.0    1.0    1.0    1.0    0.0    0.0    0.0   \n",
       "worser       1.0    0.0    0.0    1.0    1.0    1.0    0.0    0.0    0.0   \n",
       "calpurnia    0.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "angels       0.0    0.0    0.0    0.0    0.0    0.0    1.0    1.0    1.0   \n",
       "fools        0.0    0.0    0.0    0.0    0.0    0.0    1.0    1.0    1.0   \n",
       "fear         0.0    0.0    0.0    0.0    0.0    0.0    1.0    1.0    0.0   \n",
       "in           0.0    0.0    0.0    0.0    0.0    0.0    1.0    1.0    1.0   \n",
       "rush         0.0    0.0    0.0    0.0    0.0    0.0    1.0    1.0    1.0   \n",
       "to           0.0    0.0    0.0    0.0    0.0    0.0    1.0    1.0    1.0   \n",
       "tread        0.0    0.0    0.0    0.0    0.0    0.0    1.0    1.0    1.0   \n",
       "where        0.0    0.0    0.0    0.0    0.0    0.0    1.0    1.0    1.0   \n",
       "\n",
       "           doc_10  \n",
       "antony        0.0  \n",
       "brutus        0.0  \n",
       "caeser        0.0  \n",
       "cleopatra     0.0  \n",
       "mercy         0.0  \n",
       "worser        0.0  \n",
       "calpurnia     0.0  \n",
       "angels        0.0  \n",
       "fools         1.0  \n",
       "fear          1.0  \n",
       "in            1.0  \n",
       "rush          1.0  \n",
       "to            1.0  \n",
       "tread         1.0  \n",
       "where         1.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "term_freq_df = create_term_frequency_dataframe(positional_index, stemmed_dict)\n",
    "term_freq_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WEIGHTED TF TABLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_TF(x):\n",
    "    return math.log10(x) + 1 if x > 0 else 0\n",
    "\n",
    "def apply_weighted_term_freq_to_df(df):\n",
    "    return df.map(weighted_TF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_1</th>\n",
       "      <th>doc_2</th>\n",
       "      <th>doc_6</th>\n",
       "      <th>doc_4</th>\n",
       "      <th>doc_5</th>\n",
       "      <th>doc_3</th>\n",
       "      <th>doc_7</th>\n",
       "      <th>doc_8</th>\n",
       "      <th>doc_9</th>\n",
       "      <th>doc_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>antony</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brutus</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>caeser</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cleopatra</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mercy</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worser</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>calpurnia</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>angels</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fools</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fear</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rush</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tread</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>where</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           doc_1  doc_2  doc_6  doc_4  doc_5  doc_3  doc_7  doc_8  doc_9  \\\n",
       "antony       1.0    1.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "brutus       1.0    1.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0   \n",
       "caeser       1.0    1.0    1.0    1.0    1.0    0.0    0.0    0.0    0.0   \n",
       "cleopatra    1.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "mercy        1.0    0.0    1.0    1.0    1.0    1.0    0.0    0.0    0.0   \n",
       "worser       1.0    0.0    0.0    1.0    1.0    1.0    0.0    0.0    0.0   \n",
       "calpurnia    0.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "angels       0.0    0.0    0.0    0.0    0.0    0.0    1.0    1.0    1.0   \n",
       "fools        0.0    0.0    0.0    0.0    0.0    0.0    1.0    1.0    1.0   \n",
       "fear         0.0    0.0    0.0    0.0    0.0    0.0    1.0    1.0    0.0   \n",
       "in           0.0    0.0    0.0    0.0    0.0    0.0    1.0    1.0    1.0   \n",
       "rush         0.0    0.0    0.0    0.0    0.0    0.0    1.0    1.0    1.0   \n",
       "to           0.0    0.0    0.0    0.0    0.0    0.0    1.0    1.0    1.0   \n",
       "tread        0.0    0.0    0.0    0.0    0.0    0.0    1.0    1.0    1.0   \n",
       "where        0.0    0.0    0.0    0.0    0.0    0.0    1.0    1.0    1.0   \n",
       "\n",
       "           doc_10  \n",
       "antony        0.0  \n",
       "brutus        0.0  \n",
       "caeser        0.0  \n",
       "cleopatra     0.0  \n",
       "mercy         0.0  \n",
       "worser        0.0  \n",
       "calpurnia     0.0  \n",
       "angels        0.0  \n",
       "fools         1.0  \n",
       "fear          1.0  \n",
       "in            1.0  \n",
       "rush          1.0  \n",
       "to            1.0  \n",
       "tread         1.0  \n",
       "where         1.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weighted_term_freq_df = apply_weighted_term_freq_to_df(term_freq_df)\n",
    "weighted_term_freq_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INVERSE DOCUMENT FREQUANCY IDF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_doc_frequency_doc_inv_frequency(term_freq_df):\n",
    "    number_of_docs = len(term_freq_df.columns)\n",
    "    df = term_freq_df.sum(axis=1)\n",
    "    inverse_doc_freq = np.log10(number_of_docs / df.astype(float))\n",
    "\n",
    "    idf = pd.DataFrame(\n",
    "        {\"doc_freq\": df, \"inverse_doc_freq\": inverse_doc_freq},\n",
    "        index=term_freq_df.index,\n",
    "    )\n",
    "    return idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_freq</th>\n",
       "      <th>inverse_doc_freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>antony</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.522879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brutus</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.522879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>caeser</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.301030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cleopatra</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mercy</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.301030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worser</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.397940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>calpurnia</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>angels</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.522879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fools</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.397940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fear</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.522879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.397940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rush</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.397940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.397940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tread</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.397940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>where</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.397940</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           doc_freq  inverse_doc_freq\n",
       "antony          3.0          0.522879\n",
       "brutus          3.0          0.522879\n",
       "caeser          5.0          0.301030\n",
       "cleopatra       1.0          1.000000\n",
       "mercy           5.0          0.301030\n",
       "worser          4.0          0.397940\n",
       "calpurnia       1.0          1.000000\n",
       "angels          3.0          0.522879\n",
       "fools           4.0          0.397940\n",
       "fear            3.0          0.522879\n",
       "in              4.0          0.397940\n",
       "rush            4.0          0.397940\n",
       "to              4.0          0.397940\n",
       "tread           4.0          0.397940\n",
       "where           4.0          0.397940"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfdf = calculate_doc_frequency_doc_inv_frequency(term_freq_df)\n",
    "tfdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF.IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_tf_idf_optimized(term_freq_df, idf):\n",
    "    term_freq_inverse_doc_freq = term_freq_df.mul(idf[\"inverse_doc_freq\"], axis=0)\n",
    "    return term_freq_inverse_doc_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_1</th>\n",
       "      <th>doc_2</th>\n",
       "      <th>doc_6</th>\n",
       "      <th>doc_4</th>\n",
       "      <th>doc_5</th>\n",
       "      <th>doc_3</th>\n",
       "      <th>doc_7</th>\n",
       "      <th>doc_8</th>\n",
       "      <th>doc_9</th>\n",
       "      <th>doc_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>antony</th>\n",
       "      <td>0.522879</td>\n",
       "      <td>0.522879</td>\n",
       "      <td>0.522879</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brutus</th>\n",
       "      <td>0.522879</td>\n",
       "      <td>0.522879</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.522879</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>caeser</th>\n",
       "      <td>0.301030</td>\n",
       "      <td>0.301030</td>\n",
       "      <td>0.301030</td>\n",
       "      <td>0.301030</td>\n",
       "      <td>0.30103</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cleopatra</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mercy</th>\n",
       "      <td>0.301030</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.301030</td>\n",
       "      <td>0.301030</td>\n",
       "      <td>0.30103</td>\n",
       "      <td>0.30103</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worser</th>\n",
       "      <td>0.397940</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.397940</td>\n",
       "      <td>0.39794</td>\n",
       "      <td>0.39794</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>calpurnia</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>angels</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.522879</td>\n",
       "      <td>0.522879</td>\n",
       "      <td>0.522879</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fools</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.397940</td>\n",
       "      <td>0.397940</td>\n",
       "      <td>0.397940</td>\n",
       "      <td>0.397940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fear</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.522879</td>\n",
       "      <td>0.522879</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.522879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.397940</td>\n",
       "      <td>0.397940</td>\n",
       "      <td>0.397940</td>\n",
       "      <td>0.397940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rush</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.397940</td>\n",
       "      <td>0.397940</td>\n",
       "      <td>0.397940</td>\n",
       "      <td>0.397940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.397940</td>\n",
       "      <td>0.397940</td>\n",
       "      <td>0.397940</td>\n",
       "      <td>0.397940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tread</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.397940</td>\n",
       "      <td>0.397940</td>\n",
       "      <td>0.397940</td>\n",
       "      <td>0.397940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>where</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.397940</td>\n",
       "      <td>0.397940</td>\n",
       "      <td>0.397940</td>\n",
       "      <td>0.397940</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              doc_1     doc_2     doc_6     doc_4    doc_5    doc_3     doc_7  \\\n",
       "antony     0.522879  0.522879  0.522879  0.000000  0.00000  0.00000  0.000000   \n",
       "brutus     0.522879  0.522879  0.000000  0.522879  0.00000  0.00000  0.000000   \n",
       "caeser     0.301030  0.301030  0.301030  0.301030  0.30103  0.00000  0.000000   \n",
       "cleopatra  1.000000  0.000000  0.000000  0.000000  0.00000  0.00000  0.000000   \n",
       "mercy      0.301030  0.000000  0.301030  0.301030  0.30103  0.30103  0.000000   \n",
       "worser     0.397940  0.000000  0.000000  0.397940  0.39794  0.39794  0.000000   \n",
       "calpurnia  0.000000  1.000000  0.000000  0.000000  0.00000  0.00000  0.000000   \n",
       "angels     0.000000  0.000000  0.000000  0.000000  0.00000  0.00000  0.522879   \n",
       "fools      0.000000  0.000000  0.000000  0.000000  0.00000  0.00000  0.397940   \n",
       "fear       0.000000  0.000000  0.000000  0.000000  0.00000  0.00000  0.522879   \n",
       "in         0.000000  0.000000  0.000000  0.000000  0.00000  0.00000  0.397940   \n",
       "rush       0.000000  0.000000  0.000000  0.000000  0.00000  0.00000  0.397940   \n",
       "to         0.000000  0.000000  0.000000  0.000000  0.00000  0.00000  0.397940   \n",
       "tread      0.000000  0.000000  0.000000  0.000000  0.00000  0.00000  0.397940   \n",
       "where      0.000000  0.000000  0.000000  0.000000  0.00000  0.00000  0.397940   \n",
       "\n",
       "              doc_8     doc_9    doc_10  \n",
       "antony     0.000000  0.000000  0.000000  \n",
       "brutus     0.000000  0.000000  0.000000  \n",
       "caeser     0.000000  0.000000  0.000000  \n",
       "cleopatra  0.000000  0.000000  0.000000  \n",
       "mercy      0.000000  0.000000  0.000000  \n",
       "worser     0.000000  0.000000  0.000000  \n",
       "calpurnia  0.000000  0.000000  0.000000  \n",
       "angels     0.522879  0.522879  0.000000  \n",
       "fools      0.397940  0.397940  0.397940  \n",
       "fear       0.522879  0.000000  0.522879  \n",
       "in         0.397940  0.397940  0.397940  \n",
       "rush       0.397940  0.397940  0.397940  \n",
       "to         0.397940  0.397940  0.397940  \n",
       "tread      0.397940  0.397940  0.397940  \n",
       "where      0.397940  0.397940  0.397940  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = calculate_tf_idf_optimized(term_freq_df, tfdf)\n",
    "tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COSINE SIMILARITY, DOCUMENT LENGTHS, and NORMALIZATION "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(query_vector, document_vectors):\n",
    "    query_magnitude = np.linalg.norm(query_vector)\n",
    "    document_magnitudes = np.linalg.norm(document_vectors, axis=1)\n",
    "\n",
    "    dot_products = np.dot(document_vectors, query_vector)\n",
    "    cosine_similarities = dot_products / (document_magnitudes * query_magnitude)\n",
    "\n",
    "    return cosine_similarities\n",
    "\n",
    "\n",
    "def get_query_vector(query, all_words):\n",
    "    query_vector = np.zeros(len(all_words))\n",
    "    query_terms = query.split()\n",
    "\n",
    "    for term in query_terms:\n",
    "        if term in all_words:\n",
    "            query_vector[all_words.index(term)] += 1\n",
    "\n",
    "    return query_vector\n",
    "\n",
    "\n",
    "def calculate_document_lengths(term_freq_inve_doc_freq):\n",
    "    return np.sqrt((term_freq_inve_doc_freq**2).sum(axis=0))\n",
    "\n",
    "\n",
    "def normalize_term_freq_idf(term_freq_inve_doc_freq, document_lengths):\n",
    "    return term_freq_inve_doc_freq.div(document_lengths, axis=1, level=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "doc_1     1.373462\n",
       "doc_2     1.279618\n",
       "doc_6     0.674270\n",
       "doc_4     0.782941\n",
       "doc_5     0.582747\n",
       "doc_3     0.498974\n",
       "doc_7     1.223496\n",
       "doc_8     1.223496\n",
       "doc_9     1.106137\n",
       "doc_10    1.106137\n",
       "dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_lengths = calculate_document_lengths(tfidf)\n",
    "document_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_1</th>\n",
       "      <th>doc_2</th>\n",
       "      <th>doc_6</th>\n",
       "      <th>doc_4</th>\n",
       "      <th>doc_5</th>\n",
       "      <th>doc_3</th>\n",
       "      <th>doc_7</th>\n",
       "      <th>doc_8</th>\n",
       "      <th>doc_9</th>\n",
       "      <th>doc_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>antony</th>\n",
       "      <td>0.380701</td>\n",
       "      <td>0.408621</td>\n",
       "      <td>0.775474</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brutus</th>\n",
       "      <td>0.380701</td>\n",
       "      <td>0.408621</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.667839</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>caeser</th>\n",
       "      <td>0.219176</td>\n",
       "      <td>0.235250</td>\n",
       "      <td>0.446453</td>\n",
       "      <td>0.384486</td>\n",
       "      <td>0.516570</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cleopatra</th>\n",
       "      <td>0.728087</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mercy</th>\n",
       "      <td>0.219176</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.446453</td>\n",
       "      <td>0.384486</td>\n",
       "      <td>0.516570</td>\n",
       "      <td>0.603298</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worser</th>\n",
       "      <td>0.289735</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.508263</td>\n",
       "      <td>0.682869</td>\n",
       "      <td>0.797516</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>calpurnia</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.781483</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>angels</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.427365</td>\n",
       "      <td>0.427365</td>\n",
       "      <td>0.472707</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fools</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.325248</td>\n",
       "      <td>0.325248</td>\n",
       "      <td>0.359756</td>\n",
       "      <td>0.359756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fear</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.427365</td>\n",
       "      <td>0.427365</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.472707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.325248</td>\n",
       "      <td>0.325248</td>\n",
       "      <td>0.359756</td>\n",
       "      <td>0.359756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rush</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.325248</td>\n",
       "      <td>0.325248</td>\n",
       "      <td>0.359756</td>\n",
       "      <td>0.359756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.325248</td>\n",
       "      <td>0.325248</td>\n",
       "      <td>0.359756</td>\n",
       "      <td>0.359756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tread</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.325248</td>\n",
       "      <td>0.325248</td>\n",
       "      <td>0.359756</td>\n",
       "      <td>0.359756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>where</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.325248</td>\n",
       "      <td>0.325248</td>\n",
       "      <td>0.359756</td>\n",
       "      <td>0.359756</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              doc_1     doc_2     doc_6     doc_4     doc_5     doc_3  \\\n",
       "antony     0.380701  0.408621  0.775474  0.000000  0.000000  0.000000   \n",
       "brutus     0.380701  0.408621  0.000000  0.667839  0.000000  0.000000   \n",
       "caeser     0.219176  0.235250  0.446453  0.384486  0.516570  0.000000   \n",
       "cleopatra  0.728087  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "mercy      0.219176  0.000000  0.446453  0.384486  0.516570  0.603298   \n",
       "worser     0.289735  0.000000  0.000000  0.508263  0.682869  0.797516   \n",
       "calpurnia  0.000000  0.781483  0.000000  0.000000  0.000000  0.000000   \n",
       "angels     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "fools      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "fear       0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "in         0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "rush       0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "to         0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "tread      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "where      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "              doc_7     doc_8     doc_9    doc_10  \n",
       "antony     0.000000  0.000000  0.000000  0.000000  \n",
       "brutus     0.000000  0.000000  0.000000  0.000000  \n",
       "caeser     0.000000  0.000000  0.000000  0.000000  \n",
       "cleopatra  0.000000  0.000000  0.000000  0.000000  \n",
       "mercy      0.000000  0.000000  0.000000  0.000000  \n",
       "worser     0.000000  0.000000  0.000000  0.000000  \n",
       "calpurnia  0.000000  0.000000  0.000000  0.000000  \n",
       "angels     0.427365  0.427365  0.472707  0.000000  \n",
       "fools      0.325248  0.325248  0.359756  0.359756  \n",
       "fear       0.427365  0.427365  0.000000  0.472707  \n",
       "in         0.325248  0.325248  0.359756  0.359756  \n",
       "rush       0.325248  0.325248  0.359756  0.359756  \n",
       "to         0.325248  0.325248  0.359756  0.359756  \n",
       "tread      0.325248  0.325248  0.359756  0.359756  \n",
       "where      0.325248  0.325248  0.359756  0.359756  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_term_freq_idf = normalize_term_freq_idf(tfidf, document_lengths)\n",
    "normalized_term_freq_idf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST THE SEARCH ENGINE and SAVE RESULT IN TXT FILE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_query_dataframe(query_terms, normalized_term_freq_idf, tfdf):\n",
    "    query_df = pd.DataFrame(index=normalized_term_freq_idf.index)\n",
    "    query_df[\"tf\"] = [1 if term in query_terms else 0 for term in query_df.index]\n",
    "    query_df[\"w_tf\"] = query_df[\"tf\"].apply(weighted_TF)\n",
    "    query_df[\"idf\"] = tfdf[\"inverse_doc_freq\"] * query_df[\"w_tf\"]\n",
    "    query_df[\"tf_idf\"] = query_df[\"w_tf\"] * query_df[\"idf\"]\n",
    "    query_df[\"normalized\"] = query_df[\"idf\"] / np.sqrt((query_df[\"idf\"] ** 2).sum())\n",
    "    return query_df\n",
    "\n",
    "\n",
    "def calculate_product(query_df, normalized_term_freq_idf):\n",
    "    product = normalized_term_freq_idf.multiply(query_df[\"normalized\"], axis=0)\n",
    "    return product\n",
    "\n",
    "\n",
    "def calculate_cosine_similarity(product_result):\n",
    "    return product_result.sum()\n",
    "\n",
    "\n",
    "def get_related_docs(query_df, positional_index):\n",
    "    related_docs = set()\n",
    "\n",
    "    for term in query_df[query_df[\"tf\"] > 0].index:\n",
    "        if term in positional_index:\n",
    "            related_docs.update(positional_index[term][1].keys())\n",
    "\n",
    "    return list(related_docs)\n",
    "\n",
    "\n",
    "def write_to_file(file_path, content):\n",
    "    with open(file_path, \"w\") as file:\n",
    "        file.write(content)\n",
    "    print(\"Your results are printed :)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#                            PHRASE QUERY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_matching_positions(query, positional_index):\n",
    "    term_lists = [[] for _ in range(10)]\n",
    "\n",
    "    query_terms = tokenize(query)\n",
    "    print(query_terms)\n",
    "    if query_terms:\n",
    "        for term in query_terms:\n",
    "            if term not in list(stemmed_dict.values()):\n",
    "                return False\n",
    "            else:\n",
    "                for key, positions in positional_index[get_key_by_value(stemmed_dict, term)][1].items():\n",
    "                    term_lists[key - 1].extend(positions)\n",
    "\n",
    "        matching_positions = [\n",
    "            f\"doc_{pos}\"\n",
    "            for pos, positions in enumerate(term_lists, start=1)\n",
    "            if len(positions) == len(query_terms)\n",
    "        ]\n",
    "\n",
    "        return f'{\", \".join(matching_positions)}'\n",
    "    else:\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "False\n",
      "[]\n",
      "False\n",
      "[]\n",
      "False\n",
      "[]\n",
      "False\n",
      "['to']\n",
      "doc_7, doc_8, doc_9, doc_10\n",
      "\n",
      "            Vector Space Model for Query:\n",
      "    tf  w_tf      idf   tf_idf  normalized\n",
      "to   1   1.0  0.39794  0.39794         1.0\n",
      "\n",
      "\n",
      "            Product Sum:\n",
      "doc_7     0.325248\n",
      "doc_8     0.325248\n",
      "doc_9     0.359756\n",
      "doc_10    0.359756\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "            Product (query * matched doc):\n",
      "       doc_7     doc_8     doc_9    doc_10\n",
      "to  0.325248  0.325248  0.359756  0.359756\n",
      "\n",
      "\n",
      "            Similarity:\n",
      "doc_7     0.325248\n",
      "doc_8     0.325248\n",
      "doc_9     0.359756\n",
      "doc_10    0.359756\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "            Query Length:\n",
      "0.3979400086720376\n",
      "\n",
      "\n",
      "Related Docs:\n",
      "doc_7, doc_8, doc_9, doc_10\n"
     ]
    }
   ],
   "source": [
    "end_search = \"\"\n",
    "while end_search not in [\"q\", \"Q\"]:\n",
    "    query = input(\"In the Phrase Query stage Search for: \")\n",
    "    related_docs_PQ_stage = find_matching_positions(query, positional_index)\n",
    "    query_terms = tokenize(query)\n",
    "    print(related_docs_PQ_stage)\n",
    "    if related_docs_PQ_stage:\n",
    "        # save the result for Phrase query\n",
    "        document_lengths = calculate_document_lengths(tfidf)\n",
    "        normalized_term_freq_idf = normalize_term_freq_idf(tfidf, document_lengths)\n",
    "        query_df = create_query_dataframe(query_terms, normalized_term_freq_idf, tfdf)\n",
    "        product_result = calculate_product(query_df, normalized_term_freq_idf)\n",
    "        similarity = calculate_cosine_similarity(product_result)\n",
    "        try:\n",
    "            query_detailed = query_df.loc[query_terms]\n",
    "            # Write results to a text file\n",
    "            results_content = f\"\"\"\n",
    "            Vector Space Model for Query:\\n{query_detailed}\\n\\n\n",
    "            Product Sum:\\n{(product_result.sum()).loc[related_docs_PQ_stage.split(\", \"),]}\\n\\n\n",
    "            Product (query * matched doc):\\n{product_result.loc[query_terms, related_docs_PQ_stage.split(\", \")]}\\n\\n\n",
    "            Similarity:\\n{similarity.loc[related_docs_PQ_stage.split(\", \"),]}\\n\\n\n",
    "            Query Length:\\n{math.sqrt(sum(query_df['idf'] ** 2))}\\n\"\"\"\n",
    "            results_content += f\"\\n\\nRelated Docs:\\n{related_docs_PQ_stage}\"\n",
    "            print(results_content)\n",
    "            end_search = input(\"If you want to EXIT enter q/Q: \")\n",
    "        except KeyError:\n",
    "            print(f\"No such query found in the database:{query_terms}\")\n",
    "    else:\n",
    "        results_content = f\"No such query found in the database:{query_terms}\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyterlab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
